{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ParallelRunStep with a little touch of HyperDrive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to the AzureML Workspace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "\n",
    "# ws = Workspace.get(\n",
    "#                     name='mlgeek-ws', \n",
    "#                     subscription_id='e40e1658-df4f-4dfc-b90f-158e55336daa', \n",
    "#                     resource_group='mlgeek-rg',\n",
    "#                     location='eastus')\n",
    "\n",
    "# Write the workspace to a file\n",
    "# ws.write_config(path='../')   \n",
    "\n",
    "# Set up workspace\n",
    "ws = Workspace.from_config()              \n",
    "\n",
    "# Connect to the default datastore\n",
    "default_dstore = ws.get_default_datastore()\n",
    "\n",
    "# Define the number of files: 1 file per model\n",
    "#n_files = 50\n",
    "n_files = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the file dataset from the cleaned CSV files located in the `/data/hydroqc/clean` folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.dataset import Dataset\n",
    "\n",
    "# NOTE: clean_fds was created in the hd-pipeline-clean notebook\n",
    "clean_fds = Dataset.get_by_name(workspace=ws, name='clean_fds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the Conda environment for the HyperDrive runs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../pipelines/hyperdrive/src/train-gpu-env.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../pipelines/hyperdrive/src/train-gpu-env.yml\n",
    "name: train-gpu-env\n",
    "channels:\n",
    "    - conda-forge\n",
    "    - defaults\n",
    "dependencies:\n",
    "    - python=3.8\n",
    "    - numpy\n",
    "    - pandas\n",
    "    - holidays\n",
    "    - matplotlib\n",
    "    - scikit-learn\n",
    "    - pip\n",
    "    - pip:\n",
    "        - azureml-sdk\n",
    "        - tensorflow-gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an AzureML environment from the Conda YAML file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an environment\n",
    "# NOTE: PRS don't need GPU\n",
    "from azureml.core import Environment\n",
    "\n",
    "train_env = Environment(name=\"train-env\").from_conda_specification(\n",
    "                                                    name='train-env',\n",
    "                                                    file_path='../pipelines/hyperdrive/src/train-env.yml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the PRS compute instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing \"prs-ci\" compute instance. Use it.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from azureml.core.compute import ComputeInstance\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "# Choose a name for your compute instance (ci)\n",
    "# Compute instance name should be unique across the Azure region\n",
    "# NOTE: Need to be 16 characters or less\n",
    "ci_name = 'prs-ci'\n",
    "\n",
    "# Verify that instance does not exist already\n",
    "try:\n",
    "    compute_instance = ComputeInstance(workspace=ws, name=ci_name)\n",
    "    print('Found existing \"{}\" compute instance. Use it.'.format(ci_name))\n",
    "except ComputeTargetException:\n",
    "    compute_config = ComputeInstance.provisioning_configuration(\n",
    "            vm_size='STANDARD_F64S_V2',\n",
    "            # ssh_public_access=True,\n",
    "            ssh_public_access=False,\n",
    "            vnet_resourcegroup_name=None,\n",
    "            vnet_name=None,\n",
    "            subnet_name=None,\n",
    "            description='PRS Compute Instance',\n",
    "            assigned_user_object_id=None,\n",
    "            assigned_user_tenant_id=None)\n",
    "\n",
    "    compute_instance = ComputeInstance.create(\n",
    "                workspace=ws,\n",
    "                name=ci_name,\n",
    "                provisioning_configuration=compute_config)\n",
    "\n",
    "    compute_instance.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the details of the ParallelRunStep in the ParallelRunConfig object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.steps import ParallelRunConfig\n",
    "\n",
    "# NOTE: Python use 1 core per process\n",
    "processes_per_node = n_files\n",
    "\n",
    "# Maximum nodes available in the compute target\n",
    "# NOTE: For a compute instance, node_count = 1\n",
    "node_count = 1\n",
    "\n",
    "# NOTE: HyperDrive for the CNN takes approximatively 1h\n",
    "timeout = 100800\n",
    "\n",
    "parallel_run_config = ParallelRunConfig(\n",
    "    source_directory='../pipelines/hyperdrive/src',\n",
    "    entry_script='prs-hyperdrive-gpu.py',\n",
    "    mini_batch_size=str(n_files),\n",
    "    run_invocation_timeout=timeout,\n",
    "    error_threshold=1,\n",
    "    output_action=\"append_row\",\n",
    "    environment=train_env,\n",
    "    process_count_per_node=processes_per_node,\n",
    "    compute_target=ws.compute_targets['prs-ci'],\n",
    "    node_count=node_count,\n",
    "    run_max_try=3,\n",
    "    logging_level='DEBUG',\n",
    "    # Specify the filename for the PRS output\n",
    "    append_row_file_name='prs-train.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a ParallelRunStep from the ParallelRunConfig object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.data import OutputFileDatasetConfig\n",
    "from azureml.pipeline.steps import ParallelRunStep\n",
    "\n",
    "# Define the input for the PRS cleaning step\n",
    "input_dataset = clean_fds.take(count=n_files).as_named_input(name='clean_fds')\n",
    "\n",
    "# Define the output for the PRS training step\n",
    "prs_output_dir = OutputFileDatasetConfig(name=f'train_prs_output', \n",
    "                                     # Write PRS output to default datastore\n",
    "                                     destination=(default_dstore, '/data/hydroqc/prs/train/output'), \n",
    "                                     source=None)                            \n",
    "\n",
    "# Define the PRS step\n",
    "parallel_run_step = ParallelRunStep(\n",
    "    name=f\"train_prs\",\n",
    "    parallel_run_config=parallel_run_config,\n",
    "    inputs=[input_dataset.as_mount(path_on_compute=f'/tmp/{input_dataset.name}/')],\n",
    "    output=prs_output_dir,\n",
    "    allow_reuse=False,\n",
    "    arguments=None) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a compute instance for hyperdrive runs (1 file ==> 1 compute instance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing \"hd1-K80-gpu-ci\" compute instance. Use it.\n",
      "Found existing \"hd2-K80-gpu-ci\" compute instance. Use it.\n"
     ]
    }
   ],
   "source": [
    "# Choose a name for your compute instance (ci)\n",
    "# Compute instance name should be unique across the Azure region\n",
    "# NOTE: Need to be 16 characters or less\n",
    "for i in range(1, n_files + 1):\n",
    "    ci_name = f'hd{i}-K80-gpu-ci'\n",
    "\n",
    "    # Verify that instance does not exist already\n",
    "    try:\n",
    "        compute_instance = ComputeInstance(workspace=ws, name=ci_name)\n",
    "        print('Found existing \"{}\" compute instance. Use it.'.format(ci_name))\n",
    "    except ComputeTargetException:\n",
    "        compute_config = ComputeInstance.provisioning_configuration(\n",
    "                # vm_size='STANDARD_NC24RS_V3',\n",
    "                vm_size='Standard_NC6',\n",
    "                ssh_public_access=False,\n",
    "                vnet_resourcegroup_name=None,\n",
    "                vnet_name=None,\n",
    "                subnet_name=None,\n",
    "                description='HyperDrive Compute Instance',\n",
    "                assigned_user_object_id=None,\n",
    "                assigned_user_tenant_id=None)\n",
    "\n",
    "        compute_instance = ComputeInstance.create(\n",
    "                workspace=ws,\n",
    "                name=ci_name,\n",
    "                provisioning_configuration=compute_config)\n",
    "\n",
    "        compute_instance.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start the compute instances!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the PRS compute instance\n",
    "if ws.compute_targets['prs-ci'].get_status().state != 'Running':\n",
    "    ws.compute_targets['prs-ci'].start()\n",
    "\n",
    "# Start the HyperDrive compute instances\n",
    "gpu_cis = [f'hd{i}-K80-gpu-ci' for i in range(1, n_files + 1)]\n",
    "\n",
    "for ci in gpu_cis:\n",
    "    if ws.compute_targets[ci].get_status().state != 'Running':\n",
    "        ws.compute_targets[ci].start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created step train_prs [37c9fc25][941a3dcc-98e7-4ae0-89a7-14692e437246], (This step will run and generate new outputs)\n",
      "Submitted PipelineRun b5d7b91a-ef73-4f3b-986f-bbcae798d736\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/b5d7b91a-ef73-4f3b-986f-bbcae798d736?wsid=/subscriptions/d71e4214-ad22-4df0-8289-acbc0d88408d/resourcegroups/mlops-RG/workspaces/mlops-AML-WS&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6ab1d84c5454867954b1233da908818",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_PipelineWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/runs/b5d7b91a-ef73-4f3b-986f-bbcae798d736?wsid=/subscriptions/d71e4214-ad22-4df0-8289-acbc0d88408d/resourcegroups/mlops-RG/workspaces/mlops-AML-WS&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\", \"run_id\": \"b5d7b91a-ef73-4f3b-986f-bbcae798d736\", \"run_properties\": {\"run_id\": \"b5d7b91a-ef73-4f3b-986f-bbcae798d736\", \"created_utc\": \"2021-12-01T23:02:41.42585Z\", \"properties\": {\"azureml.runsource\": \"azureml.PipelineRun\", \"runSource\": \"SDK\", \"runType\": \"SDK\", \"azureml.parameters\": \"{}\", \"azureml.continue_on_step_failure\": \"False\", \"azureml.pipelineComponent\": \"pipelinerun\"}, \"tags\": {\"azureml.pipelineComponent\": \"pipelinerun\", \"Files\": \"2\"}, \"end_time_utc\": \"2021-12-01T23:04:13.854424Z\", \"status\": \"Completed\", \"log_files\": {\"logs/azureml/executionlogs.txt\": \"https://jknmlopsamlsa.blob.core.windows.net/azureml/ExperimentRun/dcid.b5d7b91a-ef73-4f3b-986f-bbcae798d736/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=OSPM%2Bl3ve0UJJGSOmY2GqvCU54lSYyXv0m4sN1gsHMk%3D&skoid=9963e1be-60f5-41a7-a6f7-1af88308cb08&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-12-01T19%3A28%3A50Z&ske=2021-12-03T03%3A38%3A50Z&sks=b&skv=2019-07-07&st=2021-12-02T02%3A58%3A53Z&se=2021-12-02T11%3A08%3A53Z&sp=r\", \"logs/azureml/stderrlogs.txt\": \"https://jknmlopsamlsa.blob.core.windows.net/azureml/ExperimentRun/dcid.b5d7b91a-ef73-4f3b-986f-bbcae798d736/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=rdM11JRmdyumPrHiaq9UhLJ9nIZY%2FYrlm%2FzIwx0CKdw%3D&skoid=9963e1be-60f5-41a7-a6f7-1af88308cb08&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-12-01T19%3A28%3A50Z&ske=2021-12-03T03%3A38%3A50Z&sks=b&skv=2019-07-07&st=2021-12-02T02%3A58%3A53Z&se=2021-12-02T11%3A08%3A53Z&sp=r\", \"logs/azureml/stdoutlogs.txt\": \"https://jknmlopsamlsa.blob.core.windows.net/azureml/ExperimentRun/dcid.b5d7b91a-ef73-4f3b-986f-bbcae798d736/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=QJ8Pbt9KyCWgvg48zf1dM4hfn3ewwlTkAQj8qcmzubM%3D&skoid=9963e1be-60f5-41a7-a6f7-1af88308cb08&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-12-01T19%3A28%3A50Z&ske=2021-12-03T03%3A38%3A50Z&sks=b&skv=2019-07-07&st=2021-12-02T02%3A58%3A53Z&se=2021-12-02T11%3A08%3A53Z&sp=r\"}, \"log_groups\": [[\"logs/azureml/executionlogs.txt\", \"logs/azureml/stderrlogs.txt\", \"logs/azureml/stdoutlogs.txt\"]], \"run_duration\": \"0:01:32\", \"run_number\": \"368\", \"run_queued_details\": {\"status\": \"Finished\", \"details\": null}}, \"child_runs\": [{\"run_id\": \"d0ea88fc-c1db-4f66-b4d5-021d85e5ea5b\", \"name\": \"train_prs\", \"status\": \"Finished\", \"start_time\": \"2021-12-01T23:02:50.021456Z\", \"created_time\": \"2021-12-01T23:02:43.357679Z\", \"end_time\": \"2021-12-01T23:04:12.295185Z\", \"duration\": \"0:01:28\", \"run_number\": 369, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2021-12-01T23:02:43.357679Z\", \"is_reused\": \"\"}], \"children_metrics\": {\"categories\": null, \"series\": null, \"metricName\": null}, \"run_metrics\": [], \"run_logs\": \"[2021-12-01 23:02:43Z] Submitting 1 runs, first five are: 37c9fc25:d0ea88fc-c1db-4f66-b4d5-021d85e5ea5b\\n[2021-12-01 23:04:13Z] Completing processing run id d0ea88fc-c1db-4f66-b4d5-021d85e5ea5b.\\n\\nRun is completed.\", \"graph\": {\"datasource_nodes\": {\"7d61c3a3\": {\"node_id\": \"7d61c3a3\", \"name\": \"1265f8d2-7752-47c1-9268-82f901aa1ef2\"}}, \"module_nodes\": {\"37c9fc25\": {\"node_id\": \"37c9fc25\", \"name\": \"train_prs\", \"status\": \"Finished\", \"_is_reused\": false, \"run_id\": \"d0ea88fc-c1db-4f66-b4d5-021d85e5ea5b\"}}, \"edges\": [{\"source_node_id\": \"7d61c3a3\", \"source_node_name\": \"1265f8d2-7752-47c1-9268-82f901aa1ef2\", \"source_name\": \"data\", \"target_name\": \"clean_fds\", \"dst_node_id\": \"37c9fc25\", \"dst_node_name\": \"train_prs\"}], \"child_runs\": [{\"run_id\": \"d0ea88fc-c1db-4f66-b4d5-021d85e5ea5b\", \"name\": \"train_prs\", \"status\": \"Finished\", \"start_time\": \"2021-12-01T23:02:50.021456Z\", \"created_time\": \"2021-12-01T23:02:43.357679Z\", \"end_time\": \"2021-12-01T23:04:12.295185Z\", \"duration\": \"0:01:28\", \"run_number\": 369, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2021-12-01T23:02:43.357679Z\", \"is_reused\": \"\"}]}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.36.0\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from azureml.core import Experiment\n",
    "from azureml.widgets import RunDetails\n",
    "from azureml.pipeline.core import Pipeline\n",
    "\n",
    "# Create the experiment\n",
    "experiment = Experiment(workspace=ws, name='prs-hyperdrive-gpu')\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = Pipeline(workspace=ws, steps=[parallel_run_step])\n",
    "\n",
    "# Launch the experiment\n",
    "# NOTE: Return azureml.pipeline.core.run.PipelineRun\n",
    "pipeline_run = experiment.submit(pipeline, tags={'Files': str(n_files)})\n",
    "\n",
    "# See the interactive logs\n",
    "RunDetails(run_instance=pipeline_run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HyperDrive Runs Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.hyperdrive import HyperDriveRun\n",
    "\n",
    "# Get the child runs of the PRS training step\n",
    "child_runs = list(pipeline_run.find_step_run(name='train_prs')[0].get_children(recursive=False))\n",
    "\n",
    "# Transform the child runs into a list of HyperDriveRun objects\n",
    "hd_runs = [HyperDriveRun(experiment=experiment, run_id=child_run.id) for child_run in child_runs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2150f937eb6d48a98e7b795504e8baf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_HyperDriveWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"loading\": true}"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "RunDetails(run_instance=hd_runs[0]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Print the run details for each hyerdrive run\n",
    "# # NOTE: Large output in the notebook!\n",
    "# for (i, hd_run) in enumerate(hd_runs):\n",
    "#     print(f'HyperDrive #{i + 1}:')\n",
    "#     print(len(f'HyperDrive #{i + 1}:')*'-')\n",
    "#     RunDetails(run_instance=hd_run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register the best model from the HyperDrive Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from azureml.core.model import Model\n",
    "\n",
    "# for hd_run in hd_runs:\n",
    "#     # Get the best model from HyperDrive run\n",
    "#     best_run = hd_run.get_best_run_by_primary_metric()\n",
    "\n",
    "#     # Select the tags from the HyperDrive run\n",
    "#     model_tag = {k: best_run.get_tags()[k] for k in ['model', 'lclid', 'id']}\n",
    "\n",
    "#     # Register the best model with tags\n",
    "#     best_run.register_model(\n",
    "#                 model_name=f'TFKeras-K80-CNN-{model_tag[\"lclid\"]}', \n",
    "#                 model_path='models/', \n",
    "#                 model_framework=Model.Framework.TENSORFLOW, \n",
    "#                 model_framework_version='2.6', \n",
    "#                 tags=model_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop all compute instances!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_cis = [ci  for ci in ws.compute_targets.keys() if 'gpu-ci' in ci]\n",
    "\n",
    "for ci in gpu_cis:\n",
    "    if ws.compute_targets[ci].get_status().state != 'Stopped':\n",
    "        ws.compute_targets[ci].stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws.compute_targets['prs-ci'].stop()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "118c77447772c081b6503c83dd0737da5b793533ed079f275de9ff3d9eb32635"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('hydroqc-env': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
